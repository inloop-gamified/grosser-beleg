\chapter{Evaluation}\label{ch:evaluation}

Zur Validierung des Konzeptes sowie der prototypischen Umsetzung wurde ein zweikomponentiges Evaluationskonzept erstellt, welches sich zusammensetzt aus einer am Prototypen durchgeführten Expertenevaluation sowie einer umfragenbasierten Studierendenevaluation. Die Expertenevaluation ist hierbei qualitativ orientiert, während über die Studierendenevaluation durch Umfragen eine quantitative Analyse durchgeführt wurde. Im Zentrum der Evaluation stand hierbei die Klärung der in \Cref{sec:ff} formulierten Forschungsfragen, auf welche zum Schluss dieses Kapitels eingegangen werden soll. Zunächst sollen jedoch nachfolgend die einzelnen Teilevaluationen sowie deren Ergebnisse erläutert und auf potenzielle Gefahren für die Validität hingewiesen werden.

\section{Expertenevaluation}

\subsection{Evaluationsstrategie und Durchführung}

Für die Expertenevaluation wurden drei Experten akquiriert, welche die fachliche Expertise vorwiesen und INLOOP selbst bereits genutzt haben, darunter zwei Tutoren der Softwaretechnologie mit mehrjähriger didaktischer Erfahrung sowie ein angestellter Webentwickler mit Abschluss als B.Sc. an der Fakultät Informatik der TU Dresden. Die Expertenevaluation wurde in individuellen Videokonferenzen durchgeführt, bei denen der Experte jeweils auf das erweiterte INLOOP per Webbrowser zugreifen konnte. Hierzu wurde die erweiterte Anwendung über einen Netzwerktunnel verfügbar gemacht. Anhand dessen wurde anschließend eine Evaluation anhand von Methoden des Discount Usability Engineerings angewandt \cite[S. 17 ff]{nielsen_usability_1994}\cite{nielsen_applying_1995}. Hierbei wurde zunächst eine Einführung in den didaktischen Hintergrundgedanken der Erweiterung gegeben und nachfolgend eine Simplified-Thinking-Aloud Analyse durchgeführt. Dem Experten wurden mehrere Aufgaben anhand des Szenarios der Nutzung des Prototypen als Studierender gegeben, nach denen er bestimmte Interaktionen in der Webanwendung ausführen sollte. Konkreter waren die Aufgaben so gewählt, dass hierdurch die Verwendung der Gamification-Elemente in den Vordergrund gestellt wurde sowie welche Gefühle, Motivationen und sonstige Gedanken mit Fokus auf die Refaktorisierung und Erkennung von Refaktorisierungskandidaten vom Experten geäußert wurden. Als initialer Schritt der Expertenevaluation wurden die Experten hierbei gebeten, sich in der Anwendung anzumelden und sich mit der Startseite vertraut zu machen. Hierfür wurden im Voraus individuelle Accounts vorbereitet, welche für die Anmeldung verwendet werden konnten. Außerdem wurden bereits Lösungen zu einer Beispielaufgabe vorbereitet, welche bestimmte Code Smells beinhalteten. Nach der Anmeldung in der Anwendung wurden nun, beginnend mit einer Infografik auf der Startseite, individuelle Interaktionswege der Experten durch die Anwendung gewählt und diskutiert. Hierzu wurde der jeweilige Experte gebeten, alle Interpretationen und Gedanken während der Durchführung möglichst ausführlich zu äußern. Nach Abschluss einer Aufgabe wurden dem jeweiligen Experten konkrete Nachfragen zu den einzelnen Komponenten gestellt, um den gedanklichen Fokus von der eigenen Benutzung der Anwendung hin auf die didaktische Sinnhaftigkeit für Studierende zu richten und dies hierdurch besser nachvollziehen zu können. Nach Durchführung des Simplified-Thinking-Aloud wurde eine an Heuristiken orientierte Analyse durchgeführt, indem konkrete abschließende Fragen zur Erweiterung gestellt wurden. Die Ergebnisse der Expertenevaluation sollen in der nachfolgenden Sektion eruiert werden.

\subsection{Ergebnisse}

\subsubsection{Evaluation des Gesamteindrucks}

Das Game-Design der Anwendung wurde von den Experten als \enquote{gut im Workflow integriert}, \enquote{stilistisch etwas spielerisch}, daher \enquote{ein wenig anders als INLOOP}, aber auch von einem der Experten anfänglich als etwas überfordernd wahrgenommen. Bei Letzterem lag dies vor allem an der Menge der möglichen Code Smells, welche in der Wiki-Komponente der Erweiterung nach den Code-Doktoren aufgelistet sind. In der Lösungsansicht erwarteten zwei der drei Experten eine Möglichkeit, die Konsultation zu starten, welche jedoch nicht gegeben war, so dass zunächst über die Navigationsleiste und das Wartezimmer auf die Konsultation gewechselt werden musste. Ein Experte merkte an, dass die Darstellung der möglichen Punkte in der Aufgabenansicht, auch bedingt durch ein fehlendes Tutorial, nur wenig Mehrwert besäße und durch die erreichte Punktzahl ergänzt werden könnte. Das Narrativ wurde von den Experten als \enquote{witzig} und \enquote{gut rüberkommend} empfunden, vereinzelt wurden Elemente des Narratives jedoch nicht richtig interpretiert, so zum Beispiel, dass Lösungen \enquote{Patienten} darstellen, oder, dass der Nutzer selbst die Rolle eines angehenden Doktors übernimmt. Von einem der Experten wurde anfänglich fehlinterpretiert, dass beim Start einer Konsultation möglicherweise andere Nutzer einbezogen werden. Als weitere Verbesserungsmöglichkeit wurde daher vorgeschlagen, die Erweiterung durch ein Tutorial zu ergänzen, welches die Grundprinzipien des Game-Designs erklärt und mögliche Missverständnisse mitigiert. Nach erstmaliger Benutzung der Gamification-Komponenten war es den Experten jedoch auch so möglich, die Spielprinzipien weitestgehend nachzuvollziehen und intuitiv zwischen den Ansichten zu wechseln.

\subsubsection{Evaluation der Detektion und der Konsultation}

Zur Evaluation der Code-Smell-Detektion wurden die Experten zunächst gebeten, in einer vorbereiteten Lösung nach potenziellen Fehlern zu suchen. Die Experten nannten zu der Lösung nach kurzer Zeit mehrere Code Smells. Nach Abschicken der Lösung öffneten die Experten die Konsultationsansicht und informierten sich über die von den Code-Doktoren angemerkten Code Smells. Das hierbei angewandte Punktesystem und, dass der Punktabzug von den Code Smells stammt, wurde von den Experten richtig interpretiert. Die detektierten Code Smells überschnitten sich hierbei mit den vorher genannten Code Smells, teils wurden vom Experten weitere Anmerkungen gemacht (zum Beispiel zur Einrückung), welche nicht detektiert wurden. Bestimmte Detektionen wurden von den Experten nicht im Voraus erkannt, so zum Beispiel das Vorhandensein eines öffentlichen Konstruktors in einer Klasse ohne Objektfunktionalitäten (Utility-Klasse). Manche Detektionen wurden als \enquote{abhängig von der persönlichen Meinung zum Stil} eingeschätzt. Dies stellt ein Problem dar, welches bereits durch Dietz et al. bei der Auswahl der Codierungsrichtlinien aus QualityReview versucht wurde, zu mitigieren \cite{dietz_teaching_2018}. Bei der konkreten Anmerkung des Experten handelte es sich um die Prüfung auf das Vorhandensein von geschweiften Klammern um ein if-Statement, welche jedoch nicht nur stilistisch begründet ist, sondern auch in der potenziellen Degradation der Wartbarkeit (siehe \Cref{sec:code-smell-extraktion}). Die hierfür durch die Erklärungsdatenbank ergänzten Erklärungen der Code Smells wurden von den Experten als vor allem für unerfahrene Studierende sinnvolle Ergänzungen zu den Titeln der Detektionen bewertet. Im oben genannten konkreten Beispiel bei der Detektion der geschweiften Klammern um ein if-Statement klärte sich der Grund hinter der Detektion auch durch das Lesen der Erklärung. Das Verständnis der Erklärungen ist laut den Experten auch abhängig von der Programmiererfahrung, da bestimmte Fachbegriffe unter Umständen nicht bekannt seien. Als weitere Verbesserungsmöglichkeit der Erklärungen schlugen die Experten daher die Ergänzung von konkreten Code-Beispielen zu den jeweiligen Regeln vor, welche die Grundgedanken hinter diesen, vor allem für unerfahrene Programmierer, besser illustrieren könnten.

\subsubsection{Evaluation der Motivationswirkung}

Nach Ende der anfänglichen Kennenlernphase bestätigten die Experten das Vorhandensein des Bedürfnisses, die Codequalität der Beispielaufgabe zu verbessern und zu perfektionieren. Einer der Experten führte selbstständig (ohne Instruktion von außen) mehrere Iterationen zwischen der Konsultation und der Bearbeitungsansicht durch, um für die Beispielaufgabe eine \enquote{gesunde} Lösung zu erhalten. Die Motivation für diese kontinuierliche Reiteration der Lösung begründete sich laut des Experten auf dem kompetitiven Charakter des Game-Designs und darauf, dass er hierbei \enquote{perfektionistisch} sei. Der Experte wollte \enquote{im Leaderboard erster sein} und durch die Verbesserung der Lösung möglichst viele \enquote{Punkte} und \enquote{Level} erreichen. Auch die anderen Elemente der Gamification kontribuieren hierbei, so wurde zum Beispiel den erreichbaren Errungenschaften im positiven Sinne ein \enquote{gewisser Sammelcharakter} zugesprochen. Die Benennung der Errungenschaften wurde als witzig und auflockernd empfunden. Die Experten versuchten intuitiv, die rätselhaft formulierten Beschreibungen der Errungenschaften zu entschlüsseln und zeigten dadurch wiederum verstärktes Interesse an diesen. Zum Schluss wurden die Experten befragt, ob die Erweiterung bei Studierenden motivierend wirken könnte, so dass diese selbstständig Code Smells identifizieren und refaktorisieren. Die Experten stimmten dem zu und bewerteten das Gamification-Konzept als sinnvolle Erweiterung für INLOOP, um die Codequalität mehr in den didaktischen Fokus zu integrieren. Gleichzeitig äußerten die Experten die Vermutung, dass dies möglicherweise nicht gleich auf alle Studierende wirken würde. Studierende, welche \enquote{lediglich Bonuspunkte für die Klausur erreichen} wöllten, oder generell ein geringes Interesse an der Bearbeitung der INLOOP-Aufgaben zeigten, würden vermutlich im Gegensatz zu engagierteren und \enquote{an Knobelei interessierten} Studierenden eher weniger durch die Gamification-Erweiterung motiviert werden oder diese nur selten nutzen, so die Experten. Zusammenfassend befanden die Experten die Gamification-Erweiterung jedoch \enquote{definitiv [für] eine Verbesserung}, um die laut den Experten wichtige Codequalität mehr in den Vordergrund zu rücken und die \enquote{Fehleranfälligkeit zu reduzieren}.

\section{Studierendenevaluation}

\subsection{Evaluationsstrategie und Durchführung}

Die Studierendenevaluation wurde auf Basis von Fragebögen umgesetzt. Die Fragebögen enthielten drei Sektionen, darunter zunächst allgemeine Fragen zum Interesse an der Berücksichtigung einer guten Codequalität bei dem Einreichen von Lösungen, danach die Bewertung der Sinnhaftigkeit einer Violation sowie deren Erklärung anhand eines Codebeispiels, und schließlich konkrete Fragen zur Motivation zentraler Elemente des Game-Designs. Um im mittleren Teil eine hinreichende Aussagekraft über die Qualität der Beschreibungen aus der Erklärungsdatenbank zu erreichen, wurden zu öffentlich verfügbaren INLOOP-Lösungen verschiedener Nutzer mithilfe der integrierten Analyse- und Parser-Infrastruktur verschiedene Violations und deren dazugehörigen Erklärungen ermittelt, um diese im Rahmen der Fragebögen Nutzern individuell zu präsentieren. Die gefundenen Violations wurden jeweils einer Umfrage zugeordnet, so dass 1006 mögliche Umfragen generiert wurden. Die Umfragen wurden anschließend auf der Plattform fragenautom.at\footnote{fragenautom.at. \url{https://fragenautom.at/} (Abgerufen am 1.9.2020)} integriert\footnote{GitHub. \url{https://github.com/inloop-gamified/website} (Abgerufen am 14.9.2020)}, jeweils versehen mit einem individuellen Zugangsschlüssel. Die individuellen, anonymisierten Umfragelinks wurden per E-Mail auf Grundlage von \S 18 Absatz 2 der IT-Ordnung der TU Dresden an 243 INLOOP-Nutzer verteilt. Bei der Selektion der Nutzer wurde das Kriterium angewandt, dass diese im laufenden Sommersemester 2020 mindestens eine INLOOP-Aufgabe des \enquote{Exam} Schwierigkeitsgrads gelöst haben mussten, um sicherzugehen, dass sich diese Nutzer bereits ausreichend mit der Basisplattform und deren Prinzipien auskennen. Die Ergebnisse sind in den Folgenden Sektionen visuell aufbereitet.

\subsection{Ergebnisse}

\subsubsection{Evaluation der Detektion}\label{sec:eva-detektionen}

Zur Detektion der Violations wurden öffentlich verfügbare oder für diesen Zweck zur Verfügung gestellte Lösungen von vier verschiedenen Nutzern mithilfe der in QualityReview bereitgestellten Checkstyle-Regeln analysiert.

\begin{figure}[H]
\includegraphics[width=\linewidth, bb=0 0 720 432]{detektionen.pdf}
\caption{Absolute Detektionsraten von auf Violations abgebildeten Checkstyle-Regeln anhand von analysierten INLOOP-Lösungen.}\label{fig:eva-detektionen}
\end{figure}

\noindent In \Cref{fig:eva-detektionen} sind die absoluten Anzahlen der hierbei detektierten Violations anhand deren Identifikator gezeigt. Die Gesamtanzahl der analysierten Codezeilen betrug 8585 Zeilen, wobei insgesamt 1006 Detektionen erzeugt wurden. Damit ermittelt sich eine Sensitivität von einer Detektion pro 8,5 Codezeilen, oder eine Detektionswahrscheinlichkeit von 11,7\%. Anhand der vertikalen Skala lässt sich erkennen, dass die mit Abstand am häufigsten erkannte Violation den Identifikator \enquote{NeedBraces} besitzt. Diese Violation prüft auf das Vorhandensein von geschweiften Klammern um bestimmte Kontrollstrukturen. Bemerkenswert ist auch, dass mehr als die Hälfte der möglichen Violation-Identifikatoren in der Stichprobe nicht detektiert wurden. Im Kontext der Umfragegenerierung wurden die Detektionen nachfolgend zufällig für eine möglichst anwendungsnahe Evaluation ausgewählt.

\subsubsection{Evaluation des Interesse an der Codequalität}

\paragraph{Anmerkung.} Die nachfolgend gezeigten Umfrageergebnisse wurden nach Heiberger und Robbins \cite{heiberger_design_2014} visuell aufbereitet. Hierbei werden die Ergebnisse der Likert-Skalen in drei Sektionen unterteilt (eher negativ, neutral, eher positiv), als Bar-Chart geplottet und entsprechend eingefärbt. Die Skala und Position kann hierbei variieren, im Rahmen dieser Evaluation wurden die Daten so skaliert, dass diese in der horizontalen Ausdehnung insgesamt 100\% der Befragten ergeben. Diese Darstellung eignet sich besonders gut, da sich so an der 50\% Marke direkt der Median als statistischer Mittelwert ablesen lässt.

Im einleitenden Teil der Umfragen wurde analysiert, inwiefern die Codequalität bei der bisherigen Bearbeitung der INLOOP-Aufgaben bereits berücksichtigt wurde.

\begin{figure}[H]
\begin{tabular}{ll}
\includegraphics[width=0.49\linewidth, bb=20 0 450 180]{distribution-0.pdf}
&
\includegraphics[width=0.49\linewidth, bb=20 0 450 180]{distribution-1.pdf}
\end{tabular}
\caption{Umfrageergebnisse zur Berücksichtigung von Codequalität bei der Lösung von INLOOP-Aufgaben.}\label{fig:umfrage-einleitung}
\end{figure}

\noindent Die statistische Aufbereitung in \Cref{fig:umfrage-einleitung} zeigt, dass die Codequalität bei der Mehrheit der Befragten häufiger berücksichtigt wurde, während sieben Befragte selten und zwei Befragte noch nie auf ihre Codequalität geachtet haben. Zum Empfinden der Wichtigkeit von Codequalität beim Bearbeitungsprozess antworteten die Befragten differenzierter, wobei auch hier ein überwiegender Teil der Nutzer Codequalität als eher wichtig einschätzen. Drei der Befragten antworteten, dass für sie Codequalität unwichtig ist, während fünf der Befragten sie eher als unwichtig einschätzen würden.

\subsubsection{Evaluation der Erklärungsdatenbank}

Für die Auswertung der Erklärungsdatenbank erhielt jeder Umfrageteilnehmer eine, im Voraus anhand von INLOOP-Lösungen generierte, Violation zur Bewertung der Sinnhaftigkeit der Detektion und der dazugehörigen Erklärung. Dazu wurde für die visuelle Repräsentation der Violation die entsprechende UI-Komponente der Konsultation aus der Gamification-Erweiterung nachempfunden, so dass sowohl Code, Code-Doktor, die in Checkstyle generierte Meldung sowie die Erklärung aus der Erklärungsdatenbank gezeigt wurden.

\begin{figure}[H]
\begin{tabular}{ll}
\includegraphics[width=0.49\linewidth, bb=20 0 450 180]{distribution-2.pdf}
&
\includegraphics[width=0.49\linewidth, bb=20 0 450 180]{distribution-3.pdf}
\end{tabular}
\caption{Umfrageergebnisse zur semantischen Code-Smell-Detektion.}\label{fig:umfrage-edb}
\end{figure}

\noindent In \Cref{fig:umfrage-edb} ist das kumulative Ergebnis dieser Analyse gezeigt, wobei etwas weniger als ein Viertel der Befragten die Checkstyle-Anmerkung als nicht sinnvoll oder eher nicht sinnvoll befanden. Die aus der Erklärungsdatenbank stammende Erklärung wurde hingegen überwiegend als hilfreich oder sehr hilfreich bewertet.

\begin{figure}[H]
\centering
\includegraphics[width=0.49\linewidth, bb=0 0 450 180]{distribution-4.pdf}
\caption{Umfrageergebnis zur Attraktivität der Code-Smell-Konsultation.}\label{fig:umfrage-konsultation}
\end{figure}

\noindent Nach Analyse der Attraktivität der Code-Smell-Konsultation in \Cref{fig:umfrage-konsultation} würden circa zwei Drittel der Nutzer diese Funktionalität sehr häufig oder eher häufig nutzen. Nur zwei der Nutzer würden diese Funktionalität überhaupt nicht nutzen wollen.

\subsubsection{Evaluation des Game-Designs}

Im dritten Teil der Umfrage wurden abschließend wesentliche Elemente des Game-Designs evaluiert. Die Umfrageteilnehmer erhielten hierbei eine textuelle Einführung und kurze Erklärung und bewerteten hierzu anschließend einzelne Kernelemente des Game-Designs.

\begin{figure}[H]
\begin{tabular}{ll}
\includegraphics[width=0.49\linewidth, bb=20 0 450 180]{distribution-5.pdf}
&
\includegraphics[width=0.49\linewidth, bb=20 0 450 180]{distribution-6.pdf}
\\
\includegraphics[width=0.49\linewidth, bb=20 0 450 180]{distribution-7.pdf}
&
\includegraphics[width=0.49\linewidth, bb=20 0 450 180]{distribution-8.pdf}
\end{tabular}
\caption{Umfrageergebnisse zu Kernelementen des Game-Designs.}\label{fig:umfrage-gamedesign}
\end{figure}

\noindent In \Cref{fig:umfrage-gamedesign} sind die Umfrageergebnisse hierzu gezeigt. Als besonders positiv und stark bis eher stark motivierend bei der Refaktorisierung schätzen die Befragten klassische Gamification-Elemente (Punkte, Level und Vergleichbarkeit) im Rahmen des Konzeptes ein, wobei nur ein Befragter antwortete, dass dies überhaupt nicht motivierend wirkte. Als überwiegend motivierend schätzen die Befragten auch das konzipierte Code-Smell-Quiz ein. Auf eine potenzielle Zeitbegrenzung bei der Refaktorisierung reagierten die Befragten hingegen überwiegend ablehnend, lediglich ein Drittel der Befragten schätzen dies als Möglichkeit ein, das Interesse hieran zu steigern. Als weiteres Element im Game-Design schätzten die Befragten schließlich auch die Errungenschaften und deren Teilbarkeit mit anderen Nutzern als überwiegend motivierend ein.

\section{Gefahren für die Validität}

Um die ausgewerteten Ergebnisse der an Likert-Skalen \cite{joshi_likert_2015} angelehnten Fragen besser einschätzen zu können, wurden weitere Metaanalysen über dem Umfrageverhalten der Befragten durchgeführt, welche im Folgenden erläutert werden sollen. Insbesondere wurde hierbei analysiert, inwiefern bei der jeweiligen Beantwortung eine tendenzielle Meinungsverzerrung hätte vorliegen können, beispielsweise durch eine allgemein sehr negative oder sehr positive Einstellung gegenüber der Softwaretechnologie-Lehre oder andere Verzerrungen, beispielsweise durch die im Zeitraum kurz vor der Umfrage geschriebene Klausur Softwaretechnologie an der TU Dresden, aus der möglicherweise Frust hätte entstehen können.

\begin{figure}[H]
\includegraphics[width=0.75\linewidth, bb=0 0 576 576]{traces.pdf}
\caption{Diagramm über die Standardabweichungen der Antwortverläufe aus den erhobenen Umfragen.}\label{fig:traces}
\end{figure}

\begin{figure}[H]
\includegraphics[width=0.75\linewidth, bb=0 0 576 288]{scatter.pdf}
\caption{Scatter-Plot über die Standardabweichungen und durchschnittlichen Bewertungen der Antwortverläufe aus den erhobenen Umfragen. Farbschema nach \Cref{fig:traces}.}\label{fig:scatter}
\end{figure}

\noindent Um dies genauer nachvollziehen zu können, wurde das in \Cref{fig:traces} gezeigte Diagramm aus den erhobenen Daten erstellt, welches die Umfragehistorien der Teilnehmer sowie die Standardabweichungen der Antworthistorien als Streuungsmaß um den Mittelwert der jeweiligen Historie darstellt. Eine der Umfragen sticht hierbei besonders heraus, mit einer Standardabweichung $\sigma < 0.5$ von $\sigma \approx 0.47$. Diese Historie ist in \Cref{fig:traces} rot markiert und zeigt eine durchgängig ablehnende oder eher ablehnende Antwortauswahl. Der Median aller Standardabweichungen liegt bei $\tilde{\sigma} \approx 1.1$. Im Scatter-Plot aus \Cref{fig:scatter} sind die Standardabweichungen anhand der durchschnittlichen Umfrageauswahlen (arithmetisches Mittel) gezeigt. Hierbei zeigt sich nochmals die durchgängig negativ bewertete Umfrage (rot markiert) als äußerst distanziert von einer klar erkennbaren Hauptgruppe. In Anbetracht dessen wäre eine denkbare Verbesserung des Umfragedesigns eine gegenüber solchen Meinungsverzerrungen robustere Fragenstellungsreihenfolge gewesen, in der die ablehnende und zustimmende Seite jeweils durch die Fragestellung gegeneinander alterniert worden wäre.

Im Allgemeinen ist zu beachten, dass die durchgeführte Umfrage als statistischer Indikator für die Motivationswirkung der Elemente aus dem Game-Design zu betrachten ist, nicht als Evidenz für eine kausale Wirkung. Im Kontext der Evaluation wurden die Gamification-Elemente zwar kurz erklärt, dies gibt den Nutzern jedoch eine gewisse Freiheit in der konkreten imaginären Vorstellung des Game-Designs. Hierfür wurde die Expertenevaluation anhand des konkreten Prototypen durchgeführt, welche die Motivationswirkung des Game-Designs anhand der benutzbaren Nutzeroberfläche bestätigen konnte. Die eingeladenen Experten haben jedoch einen anderen Kenntnisstand und andere Motivationen als Studierende, so dass bestimmte Teile des Game-Designs, wie die Erklärung der Code Smells, vermutlich bei Studierenden eine höhere Relevanz tragen. Daher wurde in der Konzeption der Umfragen besonders auf die konkrete Darstellung eines Teils einer Code-Smell-Konsultation (analog zum Prototypen) geachtet, um über die Qualität und Sinnhaftigkeit dieser Komponente eine qualifiziertere Aussage treffen zu können. Da die motivative Ausrichtung des Game-Designs hochkomplexe intrinsische, extrinsische, negative und positive Wirkungen erzeugt, ist nicht auszuschließen, dass bestimmte psychologische Effekte oder weitere mögliche Probleme nicht modelliert werden konnten. Ideal wäre hierfür der Einsatz der Erweiterung in der Produktionsumgebung und (hierauf basierend) die Durchführung entsprechend konzipierter Studien.


\section{Zusammenfassung}

Im Rahmen der Expertenevaluation konnte die prototypische Implementation des Gamification-Konzeptes zeigen, dass bei der Nutzung der über das Game-Design verbundenen Komponenten ein intuitives Bedürfnis entstehen kann, Code Smells in Lösungen selbstständig zu suchen und diese gegen Belohnungen wie Punkte, Level, Errungenschaften und Rangaufstieg in den Lösungen zu refaktorisieren. Hierbei entwickelte sich die Hypothese, dass diese Motivationswirkung möglicherweise nicht gleich stark auf Studierende mit verschiedenen Mentalitäten auswirken könnte. Bei der Expertenevaluation konnte darüber hinaus festgestellt werden, dass die Sicherstellung einer guten Nutzbarkeit der Erweiterung eine zentrale Komponente in der Wahrnehmung des Game-Designs repräsentiert. Über die Simplified-Thinking-Aloud Analyse konnten hierfür konkrete Elemente der Nutzerschnittstelle identifiziert werden, welche zur Verbesserung der Nutzbarkeit, zum Beispiel durch die Ergänzung von Informationen, Links oder eines (optionalen) Tutorials, beitragen könnten. Die Ergänzung von Beschreibungen im Rahmen der semantischen Code-Smell-Extraktion wurde von den Experten als sinnvoll bewertet, um die Hintergründe der Detektionen besser nachzuvollziehen. Als mögliche Verbesserung dieses Ansatzes wurde die Ergänzung von konkreten Code-Beispielen zu den jeweiligen Regeln identifiziert.

Durch die quantitativ orientierte Studierendenevaluation wird die Hypothese gestützt, dass die Erklärungen dazu beitragen können, Code Smells besser zu verstehen und hierdurch ein besseres Gesamtverständnis für gute Codequalität didaktisch zu prägen. Die erhobenen Daten suggerieren, dass Nutzer durch die Einführung bestimmter Gamification-Elemente motiviert werden könnten und prinzipiell bereits daran interessiert sind, die Codequalität eigener Lösungen in der Konsultation zu verbessern. Die Befragten interessieren sich hierbei anhand der Umfrageergebnisse vor allem für das Erreichen von Punkten, Leveln und das Vergleichen mit anderen Nutzern. Auch gegenüber dem nicht prototypisch implementierten \enquote{Code-Smell-Quiz} zu Lösungen anderer Nutzer sind die Befragten überwiegend positiv eingestellt. Lediglich auf zeitliche Limitationen bei der Refaktorisierung einer Lösung reagierten die Befragten überwiegend negativ. Insgesamt unterstützen auch die quantitativen Umfrageergebnisse die Hypothese, dass sich die in der Expertenevaluation festgestellten Motivationseffekte auch bei Studierenden einstellen würden. Die Validierung dieser Hypothese anhand der Finalisierung des Prototypen, dessen Integration und Produktionseinführung über einen zur Validation sinnvollen Zeitraum (zum Beispiel einem Semester) kann die in dieser Arbeit durchgeführte Evaluation als Gegenstand zukünftiger Forschung weiter fortsetzen.
